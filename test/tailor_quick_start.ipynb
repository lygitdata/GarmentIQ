{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lygitdata/GarmentIQ/blob/main/test/tailor_quick_start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GarmentIQ Tailor Quick Start"
      ],
      "metadata": {
        "id": "jrn-fD7chMUe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQhSY6NJg61I"
      },
      "outputs": [],
      "source": [
        "!pip install garmentiq -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import garmentiq as giq\n",
        "from garmentiq.classification.model_definition import tinyViT\n",
        "from garmentiq.landmark.detection.model_definition import PoseHighResolutionNet\n",
        "from garmentiq.garment_classes import garment_classes\n",
        "from garmentiq.landmark.derivation.derivation_dict import derivation_dict"
      ],
      "metadata": {
        "id": "E8RxkKlsh5IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download 4 test images\n",
        "# cloth_1 and cloth_2 are short sleeve tops, cloth_3 is vest dress, cloth_4 is skirt\n",
        "!mkdir -p test_image\n",
        "!wget -q -O /content/test_image/cloth_1.jpg \\\n",
        "    https://raw.githubusercontent.com/lygitdata/GarmentIQ/refs/heads/gh-pages/asset/img/cloth_1.jpg\n",
        "!wget -q -O /content/test_image/cloth_2.jpg \\\n",
        "    https://raw.githubusercontent.com/lygitdata/GarmentIQ/refs/heads/gh-pages/asset/img/cloth_2.jpg\n",
        "!wget -q -O /content/test_image/cloth_3.jpg \\\n",
        "    https://raw.githubusercontent.com/lygitdata/GarmentIQ/refs/heads/gh-pages/asset/img/cloth_3.jpg\n",
        "!wget -q -O /content/test_image/cloth_4.jpg \\\n",
        "    https://raw.githubusercontent.com/lygitdata/GarmentIQ/refs/heads/gh-pages/asset/img/cloth_4.jpg\n",
        "\n",
        "# Download the classification model\n",
        "!mkdir -p models\n",
        "!wget -q -O /content/models/tiny_vit_inditex_finetuned.pt \\\n",
        "    https://huggingface.co/lygitdata/garmentiq/resolve/main/tiny_vit_inditex_finetuned.pt\n",
        "\n",
        "# Download the landmark detection model\n",
        "!wget -q -O /content/models/hrnet.pth \\\n",
        "    https://huggingface.co/lygitdata/garmentiq/resolve/main/hrnet.pth"
      ],
      "metadata": {
        "id": "3-b9AZr9hJyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the tailor agent\n",
        "tailor = giq.tailor(\n",
        "    input_dir=\"/content/test_image\",\n",
        "    model_dir=\"/content/models\",\n",
        "    output_dir=\"/content/output\",\n",
        "    class_dict=garment_classes,\n",
        "    do_derive=True,\n",
        "    derivation_dict=derivation_dict,\n",
        "    do_refine=True,\n",
        "    classification_model_path=\"tiny_vit_inditex_finetuned.pt\",\n",
        "    classification_model_class=tinyViT,\n",
        "    classification_model_args={\n",
        "        \"num_classes\": len(list(garment_classes.keys())),\n",
        "        \"img_size\": (120, 184),\n",
        "        \"patch_size\": 6,\n",
        "        \"resize_dim\": (120, 184),\n",
        "        \"normalize_mean\": [0.8047, 0.7808, 0.7769],\n",
        "        \"normalize_std\": [0.2957, 0.3077, 0.3081],\n",
        "    },\n",
        "    segmentation_model_name=\"lygitdata/BiRefNet_garmentiq_backup\",\n",
        "    segmentation_model_args={\n",
        "        \"trust_remote_code\": True,\n",
        "        \"resize_dim\": (1024, 1024),\n",
        "        \"normalize_mean\": [0.485, 0.456, 0.406],\n",
        "        \"normalize_std\": [0.229, 0.224, 0.225],\n",
        "        \"high_precision\": True,\n",
        "        \"background_color\": [102, 255, 102],\n",
        "    },\n",
        "    landmark_detection_model_path=\"hrnet.pth\",\n",
        "    landmark_detection_model_class=PoseHighResolutionNet(),\n",
        "    landmark_detection_model_args={\n",
        "        \"scale_std\": 200.0,\n",
        "        \"resize_dim\": [288, 384],\n",
        "        \"normalize_mean\": [0.485, 0.456, 0.406],\n",
        "        \"normalize_std\": [0.229, 0.224, 0.225],\n",
        "    },\n",
        ")\n",
        "\n",
        "# See the tailor agent's basic information\n",
        "tailor.summary()"
      ],
      "metadata": {
        "id": "NYFrZUe48hLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the measurement with refinement and derivation\n",
        "metadata, outputs = tailor.measure(save_segmentation_image=True, save_measurement_image=True)"
      ],
      "metadata": {
        "id": "F3_WQnWmCLY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the metadata\n",
        "# It makes file access much easier\n",
        "print(metadata)"
      ],
      "metadata": {
        "id": "-spavypXE5xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the masks\n",
        "# Go to /content/output/mask_image/ to see the high resolution images\n",
        "for image in metadata['mask_image']:\n",
        "  giq.landmark.plot(image_path=image, figsize=(3, 3))"
      ],
      "metadata": {
        "id": "XoK9vs-tERj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the background modified images\n",
        "# Go to /content/output/bg_modified_image to see the high resolution images\n",
        "for image in metadata['bg_modified_image']:\n",
        "  giq.landmark.plot(image_path=image, figsize=(3, 3))"
      ],
      "metadata": {
        "id": "LartOXSkEruQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the images with desired landmarks\n",
        "# Go to /content/output/measurement_image/ to see the high resolution images\n",
        "for image in metadata['measurement_image']:\n",
        "  giq.landmark.plot(image_path=image, figsize=(3, 3))"
      ],
      "metadata": {
        "id": "HF7z8tZtDAz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the measurement results in JSON format\n",
        "# Go to /content/output/measurement_json/ to see the JSON files\n",
        "import json\n",
        "\n",
        "for json_path in metadata['measurement_json']:\n",
        "    with open(json_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "        print(f\"{json_path}:\\n\")\n",
        "        print(json.dumps(data, indent=4, sort_keys=True))\n",
        "        print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "jbLD40U5ELe9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}