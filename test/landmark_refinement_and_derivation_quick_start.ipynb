{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lygitdata/GarmentIQ/blob/main/test/landmark_refinement_and_derivation_quick_start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GarmentIQ Landmark Detection Quick Start"
      ],
      "metadata": {
        "id": "jrn-fD7chMUe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQhSY6NJg61I"
      },
      "outputs": [],
      "source": [
        "!pip install garmentiq -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import garmentiq as giq\n",
        "from garmentiq.landmark.detection.model_definition import PoseHighResolutionNet\n",
        "from garmentiq.garment_classes import garment_classes"
      ],
      "metadata": {
        "id": "E8RxkKlsh5IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a vest dress image and a pretrained model\n",
        "!mkdir -p test_image\n",
        "!wget -q -O /content/test_image/cloth_3.jpg \\\n",
        "    https://raw.githubusercontent.com/lygitdata/GarmentIQ/refs/heads/gh-pages/asset/img/cloth_3.jpg\n",
        "\n",
        "!mkdir -p models\n",
        "!wget -q -O /content/models/hrnet.pth \\\n",
        "    https://huggingface.co/lygitdata/garmentiq/resolve/main/hrnet.pth"
      ],
      "metadata": {
        "id": "3-b9AZr9hJyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the image\n",
        "giq.landmark.plot(image_path=\"/content/test_image/cloth_3.jpg\", figsize=(3, 3))"
      ],
      "metadata": {
        "id": "NYFrZUe48hLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained model from Hugging Face\n",
        "HRNet = giq.landmark.detection.load_model(\n",
        "    model_path=\"/content/models/hrnet.pth\",\n",
        "    model_class=PoseHighResolutionNet()\n",
        ")\n",
        "\n",
        "# Detect predefined landmarks\n",
        "coords, maxvals, detection_dict = giq.landmark.detect(\n",
        "    class_name=\"vest dress\",\n",
        "    class_dict=garment_classes,\n",
        "    image_path=\"/content/test_image/cloth_3.jpg\",\n",
        "    model=HRNet,\n",
        "    scale_std=200.0,\n",
        "    resize_dim=[288, 384],\n",
        "    normalize_mean=[0.485, 0.456, 0.406],\n",
        "    normalize_std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "\n",
        "# Plot the detected coordinates\n",
        "giq.landmark.plot(image_path=\"/content/test_image/cloth_3.jpg\", coordinate=coords, figsize=(3, 3), color=\"green\")"
      ],
      "metadata": {
        "id": "pMGZwL-UjPPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segmentation mask is required for refinement and derivation\n",
        "# So we need to do segmentation first\n",
        "BiRefNet = giq.segmentation.load_model(\n",
        "    pretrained_model='lygitdata/BiRefNet_garmentiq_backup',\n",
        "    pretrained_model_args={'trust_remote_code': True},\n",
        "    high_precision=True\n",
        ")\n",
        "original_img, mask = giq.segmentation.extract(\n",
        "    model=BiRefNet,\n",
        "    image_path='/content/test_image/cloth_3.jpg',\n",
        "    resize_dim=(1024, 1024),\n",
        "    normalize_mean=[0.485, 0.456, 0.406],\n",
        "    normalize_std=[0.229, 0.224, 0.225],\n",
        "    high_precision=True\n",
        ")"
      ],
      "metadata": {
        "id": "y4-zd5CusfED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Refine the landmarks\n",
        "refined_coords, refined_detection_dict = giq.landmark.refine(\n",
        "    class_name=\"vest dress\",\n",
        "    detection_np=coords,\n",
        "    detection_conf=maxvals,\n",
        "    detection_dict=detection_dict,\n",
        "    mask=mask,\n",
        "    window_size=5,\n",
        "    ksize=(11, 11),\n",
        "    sigmaX=0.0\n",
        ")\n",
        "\n",
        "# Print the original coordinates and the refined coordinates\n",
        "print(\"Original coordinates:\\n\", coords)\n",
        "print(\"Refined coordinates:\\n\", refined_coords)"
      ],
      "metadata": {
        "id": "deJChHYZ7rpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Derive custom landmarks\n",
        "derived_coords, derived_detection_dict = giq.landmark.derive(\n",
        "    class_name=\"vest dress\",\n",
        "    detection_dict=refined_detection_dict,\n",
        "\t  derivation_dict=giq.landmark.derivation_dict.derivation_dict,\n",
        "    landmark_coords=refined_coords,\n",
        "    np_mask=mask\n",
        ")"
      ],
      "metadata": {
        "id": "rpKL-_2685Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Plot the derived point\n",
        "giq.landmark.plot(\n",
        "    image_path=\"/content/test_image/cloth_3.jpg\",\n",
        "    coordinate=np.concatenate((refined_coords, np.array([[derived_coords['20']]])), axis=1),\n",
        "    figsize=(3, 3),\n",
        "    color=\"green\"\n",
        ")"
      ],
      "metadata": {
        "id": "LTskt_1KwmBG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}