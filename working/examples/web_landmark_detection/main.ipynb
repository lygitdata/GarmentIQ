{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e74a1-b705-4742-9199-f45e48336cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import garmentiq as giq\n",
    "from garmentiq.landmark.detection.model_definition import PoseHighResolutionNet\n",
    "from garmentiq.garment_classes import garment_classes\n",
    "from flask_cors import CORS\n",
    "from flask import Flask, request, jsonify\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import cv2\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd59761d-ea54-4486-a960-95d1fb020350",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p /app/working/examples/web_landmark_detection/models\n",
    "if [ ! -f /app/working/examples/web_landmark_detection/models/hrnet.pth ]; then\n",
    "    wget -q -O /app/working/examples/web_landmark_detection/models/hrnet.pth \\\n",
    "        https://huggingface.co/lygitdata/garmentiq/resolve/main/hrnet.pth\n",
    "else\n",
    "    echo \"Model file already exists, skipping download.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cec29b-d894-4207-ab07-fe8fcc0a659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# load model once\n",
    "print(\"Loading HRNet modelâ€¦\")\n",
    "HRNet = giq.landmark.detection.load_model(\n",
    "    model_path=\"/app/working/examples/web_landmark_detection/models/hrnet.pth\",\n",
    "    model_class=PoseHighResolutionNet()\n",
    ")\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9392663-bd9b-4071-a500-ad4ac046d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/health')\n",
    "def health_check():\n",
    "    return jsonify({\n",
    "        \"status\": \"active\",\n",
    "        \"token\": \"a3f7d2c14e65bb2e8f01a9dc4f6c9823d279f1e05b3a6d74c0987b1c2fae3c65\",\n",
    "        \"model\": \"web_landmark_detection\",\n",
    "        \"version\": \"1.0.0\"\n",
    "    })\n",
    "\n",
    "@app.route('/landmark_detection', methods=['POST'])\n",
    "def landmark_detection():\n",
    "    files = request.files.getlist('images')\n",
    "    garment_class = request.form.get('garment_class')\n",
    "\n",
    "    images_np = []\n",
    "    images_coords = []\n",
    "\n",
    "    # Convert uploaded images to numpy arrays\n",
    "    for file in files:\n",
    "        image = Image.open(file.stream).convert('RGB')\n",
    "        image_np = np.array(image)\n",
    "        images_np.append(image_np)\n",
    "\n",
    "    # Run detection and collect coordinates\n",
    "    for img in images_np:\n",
    "        coords, _, _ = giq.landmark.detect(\n",
    "            class_name=garment_class,\n",
    "            class_dict=garment_classes,\n",
    "            image_path=img,\n",
    "            model=HRNet,\n",
    "            scale_std=200.0,\n",
    "            resize_dim=[288, 384],\n",
    "            normalize_mean=[0.485, 0.456, 0.406],\n",
    "            normalize_std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "        images_coords.append(coords)\n",
    "\n",
    "    # Annotate images and encode to base64\n",
    "    base64_images = []\n",
    "    for img, coords in zip(images_np, images_coords):\n",
    "        # Convert RGB numpy array to BGR for OpenCV drawing\n",
    "        img_annotated = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        height, width = img_annotated.shape[:2]\n",
    "        \n",
    "        # Circle radius relative to image size\n",
    "        radius = max(2, int(round(min(height, width) * 0.0125)))  # at least radius 2\n",
    "        \n",
    "        for point in coords[0]:  # coords is (1, N, 2)\n",
    "            x, y = int(round(point[0])), int(round(point[1]))\n",
    "            cv2.circle(img_annotated, (x, y), radius, (0, 255, 0), -1)  # green filled circle in BGR\n",
    "        \n",
    "        # Convert back to RGB for PIL\n",
    "        img_annotated_rgb = cv2.cvtColor(img_annotated, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(img_annotated_rgb)\n",
    "        \n",
    "        buffered = io.BytesIO()\n",
    "        pil_img.save(buffered, format=\"PNG\")\n",
    "        img_str = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "        base64_images.append(img_str)\n",
    "\n",
    "    return jsonify({\n",
    "        \"results\": base64_images\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f8ce6-82dd-4393-a588-bfbf7466cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
