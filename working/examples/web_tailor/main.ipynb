{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1331b2-f8b8-4ed0-a7c3-1d28785922a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import shutil\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import garmentiq as giq\n",
    "from garmentiq.classification.model_definition import tinyViT\n",
    "from garmentiq.landmark.detection.model_definition import PoseHighResolutionNet\n",
    "from garmentiq.garment_classes import garment_classes\n",
    "from garmentiq.landmark.derivation.derivation_dict import derivation_dict\n",
    "\n",
    "# Initialize the empty tailer object\n",
    "tailor = None\n",
    "do_refine = None\n",
    "do_derive = None\n",
    "background_color = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a359e-1014-4113-9d71-24208724573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# where we put uploads & outputs\n",
    "BASE_DIR   = 'tailor_files'\n",
    "INPUT_DIR  = os.path.join(BASE_DIR, 'input')\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, 'output')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, 'models')\n",
    "os.makedirs(INPUT_DIR,  exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59917ee5-62f3-47f0-a953-d4bec64db55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the classification model\n",
    "# Define model URLs\n",
    "classification_model_url = \"https://huggingface.co/lygitdata/garmentiq/resolve/main/tiny_vit_inditex_finetuned.pt\"\n",
    "landmark_model_url = \"https://huggingface.co/lygitdata/garmentiq/resolve/main/hrnet.pth\"\n",
    "\n",
    "# Define local file paths using MODELS_DIR\n",
    "classification_model_path = os.path.join(MODELS_DIR, \"tiny_vit_inditex_finetuned.pt\")\n",
    "landmark_model_path = os.path.join(MODELS_DIR, \"hrnet.pth\")\n",
    "\n",
    "# Function to download only if file doesn't exist\n",
    "def download_if_missing(url, destination_path):\n",
    "    if not os.path.exists(destination_path):\n",
    "        print(f\"Downloading to {destination_path}...\")\n",
    "        urllib.request.urlretrieve(url, destination_path)\n",
    "        print(\"Download complete.\")\n",
    "    else:\n",
    "        print(f\"File already exists: {destination_path}. Skipping download.\")\n",
    "\n",
    "# Perform conditional downloads\n",
    "download_if_missing(classification_model_url, classification_model_path)\n",
    "download_if_missing(landmark_model_url, landmark_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877cadd-1ffd-4ce4-9017-c2f77a8dc750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_to_base64(path):\n",
    "    with open(path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4232f4e-3b49-4ee2-b2d9-ad754c292e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/health')\n",
    "def health_check():\n",
    "    return jsonify({\n",
    "        \"status\": \"active\",\n",
    "        \"token\": \"31f21a4323cf148339669c736f522cf89fa570a2bffc80ba874078477b76f81b\",\n",
    "        \"model\": \"web_tailor\",\n",
    "        \"version\": \"1.0.0\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd94aa86-b570-4809-9078-0499750c40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/setup', methods=['POST'])\n",
    "def setup():\n",
    "    global tailor\n",
    "    global do_refine\n",
    "    global do_derive\n",
    "    global background_color\n",
    "\n",
    "    do_refine = request.form.get('do_refine') == 'true'\n",
    "    do_derive = request.form.get('do_derive') == 'true'\n",
    "    r = request.form.get('red', '')\n",
    "    g = request.form.get('green', '')\n",
    "    b = request.form.get('blue', '')\n",
    "    background_color = None\n",
    "\n",
    "    if r and g and b:\n",
    "        try:\n",
    "            rgb = [int(r), int(g), int(b)]\n",
    "            if any(c < 0 or c > 255 for c in rgb):\n",
    "                raise ValueError\n",
    "            background_color = rgb\n",
    "        except ValueError:\n",
    "            return jsonify(error='Invalid RGB values; must be integers 0â€“255'), 400\n",
    "\n",
    "    # Setup the tailor agent\n",
    "    tailor = giq.tailor(\n",
    "        input_dir=INPUT_DIR,\n",
    "        model_dir=MODELS_DIR,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        class_dict=garment_classes,\n",
    "        do_derive=do_derive,\n",
    "        derivation_dict=derivation_dict,\n",
    "        do_refine=do_refine,\n",
    "        classification_model_path=\"tiny_vit_inditex_finetuned.pt\",\n",
    "        classification_model_class=tinyViT,\n",
    "        classification_model_args={\n",
    "            \"num_classes\": len(garment_classes),\n",
    "            \"img_size\": (120, 184),\n",
    "            \"patch_size\": 6,\n",
    "            \"resize_dim\": (120, 184),\n",
    "            \"normalize_mean\": [0.8047, 0.7808, 0.7769],\n",
    "            \"normalize_std\": [0.2957, 0.3077, 0.3081],\n",
    "        },\n",
    "        segmentation_model_name=\"lygitdata/BiRefNet_garmentiq_backup\",\n",
    "        segmentation_model_args={\n",
    "            \"trust_remote_code\": True,\n",
    "            \"resize_dim\": (1024, 1024),\n",
    "            \"normalize_mean\": [0.485, 0.456, 0.406],\n",
    "            \"normalize_std\": [0.229, 0.224, 0.225],\n",
    "            \"high_precision\": True,\n",
    "            \"background_color\": background_color,\n",
    "        },\n",
    "        landmark_detection_model_path=\"hrnet.pth\",\n",
    "        landmark_detection_model_class=PoseHighResolutionNet(),\n",
    "        landmark_detection_model_args={\n",
    "            \"scale_std\": 200.0,\n",
    "            \"resize_dim\": [288, 384],\n",
    "            \"normalize_mean\": [0.485, 0.456, 0.406],\n",
    "            \"normalize_std\": [0.229, 0.224, 0.225],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return jsonify(message='Tailor setup complete'), 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233bec33-c6a0-4542-819c-72fe4f873f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/measure', methods=['POST'])\n",
    "def measure():\n",
    "    global tailor, do_refine, do_derive, background_color\n",
    "    \n",
    "    files = request.files.getlist('images')\n",
    "    if not files:\n",
    "        return jsonify(error='No images uploaded'), 400\n",
    "\n",
    "    # Ensure input/output directories are fresh\n",
    "    for d in (INPUT_DIR, OUTPUT_DIR):\n",
    "        if os.path.exists(d):\n",
    "            shutil.rmtree(d)\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "    # Save uploaded images\n",
    "    for f in files:\n",
    "        f.save(os.path.join(INPUT_DIR, f.filename))\n",
    "\n",
    "    # Run segmentation & measurement\n",
    "    metadata, _ = tailor.measure(save_segmentation_image=True, save_measurement_image=True)\n",
    "    metadata = metadata.sort_values(by='filename', ascending=True)\n",
    "\n",
    "    # Structure results\n",
    "    results = []\n",
    "    for idx, row in metadata.iterrows():\n",
    "        filename = row['filename']\n",
    "    \n",
    "        # Read & encode the JSON contents\n",
    "        json_b64 = None\n",
    "        json_path = row.get(\"measurement_json\")\n",
    "        if json_path:\n",
    "            with open(json_path, 'r') as jf:\n",
    "                text = jf.read()\n",
    "            json_b64 = base64.b64encode(text.encode('utf-8')).decode('utf-8')\n",
    "    \n",
    "        entry = {\n",
    "            \"Image name\": filename,\n",
    "            \"Class\": row.get(\"class\", None),\n",
    "            \"Measurement image\": encode_image_to_base64(row[\"measurement_image\"]),\n",
    "            \"Measurement JSON (base64)\": json_b64,\n",
    "        }\n",
    "    \n",
    "        if row.get(\"mask_image\"):\n",
    "            entry[\"Mask\"] = encode_image_to_base64(row[\"mask_image\"])\n",
    "    \n",
    "        if row.get(\"bg_modified_image\"):\n",
    "            entry[\"Background modified\"] = encode_image_to_base64(row[\"bg_modified_image\"])\n",
    "    \n",
    "        results.append(entry)\n",
    "    \n",
    "    return jsonify(results), 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677539e0-33bb-4dcd-b976-5937730e4b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5002)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
