{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrn-fD7chMUe"
   },
   "source": [
    "# GarmentIQ Tailor Quick Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8RxkKlsh5IY"
   },
   "outputs": [],
   "source": [
    "import garmentiq as giq\n",
    "from garmentiq.classification.model_definition import tinyViT\n",
    "from garmentiq.landmark.detection.model_definition import PoseHighResolutionNet\n",
    "from garmentiq.garment_classes import garment_classes\n",
    "from garmentiq.landmark.derivation.derivation_dict import derivation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-b9AZr9hJyK"
   },
   "outputs": [],
   "source": [
    "# Download 4 test images\n",
    "# cloth_1 and cloth_2 are short sleeve tops, cloth_3 is vest dress, cloth_4 is skirt\n",
    "!mkdir -p /app/working/examples/tailor_quick_start/test_image\n",
    "!wget -q -O /app/working/examples/tailor_quick_start/test_image/cloth_1.jpg \\\n",
    "    https://raw.githubusercontent.com/lygitdata/GarmentIQ/refs/heads/gh-pages/asset/img/cloth_1.jpg\n",
    "!wget -q -O /app/working/examples/tailor_quick_start/test_image/cloth_2.jpg \\\n",
    "    https://raw.githubusercontent.com/lygitdata/GarmentIQ/refs/heads/gh-pages/asset/img/cloth_2.jpg\n",
    "!wget -q -O /app/working/examples/tailor_quick_start/test_image/cloth_3.jpg \\\n",
    "    https://raw.githubusercontent.com/lygitdata/GarmentIQ/refs/heads/gh-pages/asset/img/cloth_3.jpg\n",
    "!wget -q -O /app/working/examples/tailor_quick_start/test_image/cloth_4.jpg \\\n",
    "    https://raw.githubusercontent.com/lygitdata/GarmentIQ/refs/heads/gh-pages/asset/img/cloth_4.jpg\n",
    "\n",
    "# Download the classification model\n",
    "!mkdir -p /app/working/examples/tailor_quick_start/models\n",
    "!wget -q -O /app/working/examples/tailor_quick_start/models/tiny_vit_inditex_finetuned.pt \\\n",
    "    https://huggingface.co/lygitdata/garmentiq/resolve/main/tiny_vit_inditex_finetuned.pt\n",
    "\n",
    "# Download the landmark detection model\n",
    "!wget -q -O /app/working/examples/tailor_quick_start/models/hrnet.pth \\\n",
    "    https://huggingface.co/lygitdata/garmentiq/resolve/main/hrnet.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYFrZUe48hLi"
   },
   "outputs": [],
   "source": [
    "# Setup the tailor agent\n",
    "tailor = giq.tailor(\n",
    "    input_dir=\"/app/working/examples/tailor_quick_start/test_image\",\n",
    "    model_dir=\"/app/working/examples/tailor_quick_start/models\",\n",
    "    output_dir=\"/app/working/examples/tailor_quick_start/output\",\n",
    "    class_dict=garment_classes,\n",
    "    do_derive=True,\n",
    "    derivation_dict=derivation_dict,\n",
    "    do_refine=True,\n",
    "    classification_model_path=\"tiny_vit_inditex_finetuned.pt\",\n",
    "    classification_model_class=tinyViT,\n",
    "    classification_model_args={\n",
    "        \"num_classes\": len(list(garment_classes.keys())),\n",
    "        \"img_size\": (120, 184),\n",
    "        \"patch_size\": 6,\n",
    "        \"resize_dim\": (120, 184),\n",
    "        \"normalize_mean\": [0.8047, 0.7808, 0.7769],\n",
    "        \"normalize_std\": [0.2957, 0.3077, 0.3081],\n",
    "    },\n",
    "    segmentation_model_name=\"lygitdata/BiRefNet_garmentiq_backup\",\n",
    "    segmentation_model_args={\n",
    "        \"trust_remote_code\": True,\n",
    "        \"resize_dim\": (1024, 1024),\n",
    "        \"normalize_mean\": [0.485, 0.456, 0.406],\n",
    "        \"normalize_std\": [0.229, 0.224, 0.225],\n",
    "        \"high_precision\": True,\n",
    "        \"background_color\": [102, 255, 102],\n",
    "    },\n",
    "    landmark_detection_model_path=\"hrnet.pth\",\n",
    "    landmark_detection_model_class=PoseHighResolutionNet(),\n",
    "    landmark_detection_model_args={\n",
    "        \"scale_std\": 200.0,\n",
    "        \"resize_dim\": [288, 384],\n",
    "        \"normalize_mean\": [0.485, 0.456, 0.406],\n",
    "        \"normalize_std\": [0.229, 0.224, 0.225],\n",
    "    },\n",
    ")\n",
    "\n",
    "# See the tailor agent's basic information\n",
    "tailor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3_WQnWmCLY2"
   },
   "outputs": [],
   "source": [
    "# Start the measurement with refinement and derivation\n",
    "metadata, outputs = tailor.measure(save_segmentation_image=True, save_measurement_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-spavypXE5xb"
   },
   "outputs": [],
   "source": [
    "# See the metadata\n",
    "# It makes file access much easier\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoK9vs-tERj-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the masks\n",
    "# Go to /app/working/examples/tailor_quick_start/output/mask_image/ to see the high resolution images\n",
    "for image in metadata['mask_image']:\n",
    "  giq.landmark.plot(image_path=image, figsize=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LartOXSkEruQ"
   },
   "outputs": [],
   "source": [
    "# Plot the background modified images\n",
    "# Go to /app/working/examples/tailor_quick_start/output/bg_modified_image to see the high resolution images\n",
    "for image in metadata['bg_modified_image']:\n",
    "  giq.landmark.plot(image_path=image, figsize=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HF7z8tZtDAz8"
   },
   "outputs": [],
   "source": [
    "# Plot the images with desired landmarks\n",
    "# Go to /app/working/examples/tailor_quick_start/output/measurement_image/ to see the high resolution images\n",
    "for image in metadata['measurement_image']:\n",
    "  giq.landmark.plot(image_path=image, figsize=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbLD40U5ELe9"
   },
   "outputs": [],
   "source": [
    "# See the measurement results in JSON format\n",
    "# Go to /app/working/examples/tailor_quick_start/output/measurement_json/ to see the JSON files\n",
    "import json\n",
    "\n",
    "for json_path in metadata['measurement_json']:\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        print(f\"{json_path}:\\n\")\n",
    "        print(json.dumps(data, indent=4, sort_keys=True))\n",
    "        print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
